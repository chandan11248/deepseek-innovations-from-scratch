{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd4f700",
   "metadata": {},
   "source": [
    "### What is `register_buffer`?\n",
    "\n",
    "In PyTorch, `register_buffer` is used to store non-trainable tensors as part of a model. These tensors are:\n",
    "\n",
    "- Saved and loaded with the model's `state_dict`.\n",
    "- Not updated during training (no gradients are computed for them).\n",
    "- Useful for storing constants, precomputed values, or intermediate results that are part of the model's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63ed5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer (my_constant): tensor([1., 2., 3.])\n",
      "Loaded Buffer (my_constant): tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Register a buffer to store a constant tensor\n",
    "        self.register_buffer(\"my_constant\", torch.tensor([1.0, 2.0, 3.0]))\n",
    "        \n",
    "        # A trainable parameter\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the buffer in the forward pass\n",
    "        return self.linear(x + self.my_constant)\n",
    "\n",
    "# Create the model\n",
    "model = MyModel()\n",
    "\n",
    "# Check the buffer\n",
    "print(\"Buffer (my_constant):\", model.my_constant)\n",
    "\n",
    "# Save and load the model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "loaded_model = MyModel()\n",
    "loaded_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "# Verify the buffer is loaded\n",
    "print(\"Loaded Buffer (my_constant):\", loaded_model.my_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c28f2",
   "metadata": {},
   "source": [
    "How view Works:\n",
    "Reshaping:\n",
    "\n",
    "The view method changes the shape of the tensor while keeping the same data in memory.\n",
    "The total number of elements in the tensor must remain the same before and after the reshape.\n",
    "Automatic Dimension Inference:\n",
    "\n",
    "If you specify -1 for one dimension, PyTorch will calculate its size automatically based on the other dimensions.\n",
    "Contiguity Requirement:\n",
    "\n",
    "The tensor must be contiguous in memory for view to work. If it's not, you may need to call .contiguous() before using view.\n",
    "Example:\n",
    "Output:\n",
    "\n",
    "How view is Used in Your Code:\n",
    "Input Tensor:\n",
    "\n",
    "absorbed is the result of the matrix multiplication between self.W_q.weight and self.W_uk.weight.\n",
    "Reshaping:\n",
    "\n",
    "The view method reshapes absorbed into a tensor of shape (self.n_heads, self.dh, -1).\n",
    "Here:\n",
    "self.n_heads: Number of attention heads.\n",
    "self.dh: Dimension per head (calculated as d_model // n_heads).\n",
    "-1: PyTorch automatically infers the size of the last dimension based on the total number of elements.\n",
    "Purpose:\n",
    "\n",
    "This reshaping organizes the absorbed weights into a format suitable for multi-head attention, where each head operates on its own portion of the data.\n",
    "Key Points:\n",
    "view is a lightweight operation that only changes the shape of the tensor, not the data itself.\n",
    "The total number of elements in the tensor must remain constant.\n",
    "Use -1 for PyTorch to infer the size of one dimension automatically.\n",
    "GPT-4o â€¢ 0x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c2560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "\n",
      "Reshaped Tensor:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "Reshaped Tensor with -1:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor of shape (2, 6)\n",
    "x = torch.arange(12).view(2, 6)\n",
    "print(\"Original Tensor:\")\n",
    "print(x)\n",
    "\n",
    "# Reshape to (3, 4)\n",
    "y = x.view(3, 4)\n",
    "print(\"\\nReshaped Tensor:\")\n",
    "print(y)\n",
    "\n",
    "# Reshape to (2, -1) (automatic inference for the second dimension)\n",
    "z = x.view(2, -1)\n",
    "print(\"\\nReshaped Tensor with -1:\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9402e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c21f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.rand(2,3)\n",
    "b=torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6717556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9891, 0.6920, 0.8452],\n",
       "        [0.6575, 0.5898, 0.1174]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6deb8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.stack([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62c79490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9386, 0.7886, 0.1803],\n",
       "         [0.6518, 0.0352, 0.2319]],\n",
       "\n",
       "        [[0.9891, 0.6920, 0.8452],\n",
       "         [0.6575, 0.5898, 0.1174]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e580c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b109fd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e046a950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0c7fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1, 3, 1, 5)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce216afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Size([1, 3, 1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aff88c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "y = torch.squeeze(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b618276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 1, 5)\n",
    "\n",
    "y = torch.squeeze(x, dim=2)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feccf48",
   "metadata": {},
   "source": [
    " >If the dimension is not size 1, nothing happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70528ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
